{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-27T13:17:13.869734Z",
     "iopub.status.busy": "2025-06-27T13:17:13.869423Z",
     "iopub.status.idle": "2025-06-27T13:17:23.851516Z",
     "shell.execute_reply": "2025-06-27T13:17:23.850924Z",
     "shell.execute_reply.started": "2025-06-27T13:17:13.869702Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer\n",
    "from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig, TaskType\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "# !pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:17:23.853431Z",
     "iopub.status.busy": "2025-06-27T13:17:23.852685Z",
     "iopub.status.idle": "2025-06-27T13:17:23.857342Z",
     "shell.execute_reply": "2025-06-27T13:17:23.856430Z",
     "shell.execute_reply.started": "2025-06-27T13:17:23.853409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL = \"deepseek-ai/DeepSeek-Coder-V2-Lite-Base\"\n",
    "DATA_PATH = \"/kaggle/input/linux-dataset/LINUX_TERMINAL_COMMANDS.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:17:23.858333Z",
     "iopub.status.busy": "2025-06-27T13:17:23.858093Z",
     "iopub.status.idle": "2025-06-27T13:17:24.351940Z",
     "shell.execute_reply": "2025-06-27T13:17:24.350945Z",
     "shell.execute_reply.started": "2025-06-27T13:17:23.858317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer=AutoTokenizer.from_pretrained(MODEL,trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:17:24.353748Z",
     "iopub.status.busy": "2025-06-27T13:17:24.353415Z",
     "iopub.status.idle": "2025-06-27T13:17:24.359386Z",
     "shell.execute_reply": "2025-06-27T13:17:24.358672Z",
     "shell.execute_reply.started": "2025-06-27T13:17:24.353721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load model in 4-bit (QLoRA)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:17:26.860831Z",
     "iopub.status.busy": "2025-06-27T13:17:26.860247Z",
     "iopub.status.idle": "2025-06-27T13:21:55.227522Z",
     "shell.execute_reply": "2025-06-27T13:21:55.226753Z",
     "shell.execute_reply.started": "2025-06-27T13:17:26.860806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T11:04:32.950011Z",
     "iopub.status.busy": "2025-06-27T11:04:32.949759Z",
     "iopub.status.idle": "2025-06-27T11:04:32.953311Z",
     "shell.execute_reply": "2025-06-27T11:04:32.952707Z",
     "shell.execute_reply.started": "2025-06-27T11:04:32.949991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip show bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:55.229042Z",
     "iopub.status.busy": "2025-06-27T13:21:55.228822Z",
     "iopub.status.idle": "2025-06-27T13:21:55.232402Z",
     "shell.execute_reply": "2025-06-27T13:21:55.231810Z",
     "shell.execute_reply.started": "2025-06-27T13:21:55.229025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:55.237402Z",
     "iopub.status.busy": "2025-06-27T13:21:55.237225Z",
     "iopub.status.idle": "2025-06-27T13:21:55.377541Z",
     "shell.execute_reply": "2025-06-27T13:21:55.376989Z",
     "shell.execute_reply.started": "2025-06-27T13:21:55.237387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_model = prepare_model_for_kbit_training(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:55.378468Z",
     "iopub.status.busy": "2025-06-27T13:21:55.378212Z",
     "iopub.status.idle": "2025-06-27T13:21:55.382808Z",
     "shell.execute_reply": "2025-06-27T13:21:55.382151Z",
     "shell.execute_reply.started": "2025-06-27T13:21:55.378443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"up_proj\", \"down_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:55.383752Z",
     "iopub.status.busy": "2025-06-27T13:21:55.383489Z",
     "iopub.status.idle": "2025-06-27T13:22:01.587708Z",
     "shell.execute_reply": "2025-06-27T13:22:01.587081Z",
     "shell.execute_reply.started": "2025-06-27T13:21:55.383730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(base_model, peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:01.588536Z",
     "iopub.status.busy": "2025-06-27T13:22:01.588336Z",
     "iopub.status.idle": "2025-06-27T13:22:01.891889Z",
     "shell.execute_reply": "2025-06-27T13:22:01.891336Z",
     "shell.execute_reply.started": "2025-06-27T13:22:01.588522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load and process dataset\n",
    "dataset = load_dataset(\"json\", data_files=DATA_PATH)\n",
    "dataset = dataset[\"train\"].select_columns([\"description\", \"command\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:01.892822Z",
     "iopub.status.busy": "2025-06-27T13:22:01.892614Z",
     "iopub.status.idle": "2025-06-27T13:22:01.897133Z",
     "shell.execute_reply": "2025-06-27T13:22:01.896540Z",
     "shell.execute_reply.started": "2025-06-27T13:22:01.892806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Apply chat template\n",
    "def format_with_chat_template(example):\n",
    "    messages = [\n",
    "       {\"role\": \"system\", \"content\":'''You are a CLI command translator. Given a natural language request, output only the exact command(s) needed to accomplish the task. Provide no explanations, descriptions, or additional text - just the raw command(s) that can be directly executed in a terminal.\n",
    "\n",
    "Examples:\n",
    "Input: \"list all files in current directory\"\n",
    "Output: ls -la\n",
    "\n",
    "Input: \"find all Python files\"\n",
    "Output: find . -name \"*.py\"\n",
    "\n",
    "Input: \"show running processes\"\n",
    "Output: ps aux'''},\n",
    "        {\"role\": \"user\", \"content\": example[\"description\"]},\n",
    "        {\"role\": \"assistant\", \"content\": example[\"command\"]}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    return {\"text\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:01.898179Z",
     "iopub.status.busy": "2025-06-27T13:22:01.897922Z",
     "iopub.status.idle": "2025-06-27T13:22:02.055258Z",
     "shell.execute_reply": "2025-06-27T13:22:02.054422Z",
     "shell.execute_reply.started": "2025-06-27T13:22:01.898158Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "formatted_dataset = dataset.map(format_with_chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking best sequence length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T04:12:15.165066Z",
     "iopub.status.busy": "2025-06-27T04:12:15.164458Z",
     "iopub.status.idle": "2025-06-27T04:12:15.168645Z",
     "shell.execute_reply": "2025-06-27T04:12:15.167884Z",
     "shell.execute_reply.started": "2025-06-27T04:12:15.165039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T04:12:47.863499Z",
     "iopub.status.busy": "2025-06-27T04:12:47.863202Z",
     "iopub.status.idle": "2025-06-27T04:12:47.867434Z",
     "shell.execute_reply": "2025-06-27T04:12:47.866803Z",
     "shell.execute_reply.started": "2025-06-27T04:12:47.863476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Token length distribution\n",
    "def get_token_lengths(example):\n",
    "    return {\"length\": len(tokenizer(example[\"text\"])[\"input_ids\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T04:15:42.465318Z",
     "iopub.status.busy": "2025-06-27T04:15:42.464753Z",
     "iopub.status.idle": "2025-06-27T04:15:43.078221Z",
     "shell.execute_reply": "2025-06-27T04:15:43.077424Z",
     "shell.execute_reply.started": "2025-06-27T04:15:42.465296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lengths = formatted_dataset.map(get_token_lengths)\n",
    "lengths_list = [x['length'] for x in lengths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T04:15:44.843131Z",
     "iopub.status.busy": "2025-06-27T04:15:44.842499Z",
     "iopub.status.idle": "2025-06-27T04:15:45.186354Z",
     "shell.execute_reply": "2025-06-27T04:15:45.185682Z",
     "shell.execute_reply.started": "2025-06-27T04:15:44.843105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.hist(lengths_list, bins=50)\n",
    "plt.xlabel(\"Token length\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Input Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:02.057712Z",
     "iopub.status.busy": "2025-06-27T13:22:02.057462Z",
     "iopub.status.idle": "2025-06-27T13:22:02.061407Z",
     "shell.execute_reply": "2025-06-27T13:22:02.060826Z",
     "shell.execute_reply.started": "2025-06-27T13:22:02.057695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize(example):\n",
    "    tokens = tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=192\n",
    "    )\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:02.062900Z",
     "iopub.status.busy": "2025-06-27T13:22:02.062141Z",
     "iopub.status.idle": "2025-06-27T13:22:02.391863Z",
     "shell.execute_reply": "2025-06-27T13:22:02.391107Z",
     "shell.execute_reply.started": "2025-06-27T13:22:02.062883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = formatted_dataset.map(tokenize, batched=True, remove_columns=[\"description\", \"command\", \"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preparing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T11:05:29.886953Z",
     "iopub.status.busy": "2025-06-27T11:05:29.886623Z",
     "iopub.status.idle": "2025-06-27T11:05:29.890980Z",
     "shell.execute_reply": "2025-06-27T11:05:29.890212Z",
     "shell.execute_reply.started": "2025-06-27T11:05:29.886921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "has_chat_template = hasattr(tokenizer, \"apply_chat_template\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T11:05:30.105181Z",
     "iopub.status.busy": "2025-06-27T11:05:30.104864Z",
     "iopub.status.idle": "2025-06-27T11:05:30.109437Z",
     "shell.execute_reply": "2025-06-27T11:05:30.108594Z",
     "shell.execute_reply.started": "2025-06-27T11:05:30.105143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Chat template available?\", has_chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T11:05:31.554474Z",
     "iopub.status.busy": "2025-06-27T11:05:31.553894Z",
     "iopub.status.idle": "2025-06-27T11:05:31.559431Z",
     "shell.execute_reply": "2025-06-27T11:05:31.558696Z",
     "shell.execute_reply.started": "2025-06-27T11:05:31.554449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "formatted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T11:05:38.540971Z",
     "iopub.status.busy": "2025-06-27T11:05:38.540595Z",
     "iopub.status.idle": "2025-06-27T11:05:38.545687Z",
     "shell.execute_reply": "2025-06-27T11:05:38.544953Z",
     "shell.execute_reply.started": "2025-06-27T11:05:38.540941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:02.392914Z",
     "iopub.status.busy": "2025-06-27T13:22:02.392702Z",
     "iopub.status.idle": "2025-06-27T13:22:02.404437Z",
     "shell.execute_reply": "2025-06-27T13:22:02.403774Z",
     "shell.execute_reply.started": "2025-06-27T13:22:02.392898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "split_data=tokenized_dataset.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:02.405169Z",
     "iopub.status.busy": "2025-06-27T13:22:02.404986Z",
     "iopub.status.idle": "2025-06-27T13:22:02.417127Z",
     "shell.execute_reply": "2025-06-27T13:22:02.416418Z",
     "shell.execute_reply.started": "2025-06-27T13:22:02.405155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "split_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:02.418062Z",
     "iopub.status.busy": "2025-06-27T13:22:02.417885Z",
     "iopub.status.idle": "2025-06-27T13:22:08.873242Z",
     "shell.execute_reply": "2025-06-27T13:22:08.872431Z",
     "shell.execute_reply.started": "2025-06-27T13:22:02.418049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "user_secrets= UserSecretsClient()\n",
    "my_secret = user_secrets.get_secret(\"wandb-key\") \n",
    "\n",
    "wandb.login(key=my_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:08.874707Z",
     "iopub.status.busy": "2025-06-27T13:22:08.874124Z",
     "iopub.status.idle": "2025-06-27T13:22:08.907246Z",
     "shell.execute_reply": "2025-06-27T13:22:08.906687Z",
     "shell.execute_reply.started": "2025-06-27T13:22:08.874680Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./kaggle/working/deepseek-finetuned\",\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=16,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=5,\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=5,\n",
    "    logging_steps=5,\n",
    "    report_to=\"wandb\",            \n",
    "    run_name=\"deepseek-cli-run\",  \n",
    "    ddp_find_unused_parameters=False \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:08.908280Z",
     "iopub.status.busy": "2025-06-27T13:22:08.908015Z",
     "iopub.status.idle": "2025-06-27T13:22:08.911711Z",
     "shell.execute_reply": "2025-06-27T13:22:08.910984Z",
     "shell.execute_reply.started": "2025-06-27T13:22:08.908257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:08.912760Z",
     "iopub.status.busy": "2025-06-27T13:22:08.912488Z",
     "iopub.status.idle": "2025-06-27T13:22:08.947137Z",
     "shell.execute_reply": "2025-06-27T13:22:08.946592Z",
     "shell.execute_reply.started": "2025-06-27T13:22:08.912737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_data[\"train\"],\n",
    "    eval_dataset=split_data['test'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:00:07.676101Z",
     "iopub.status.busy": "2025-06-27T16:00:07.675362Z",
     "iopub.status.idle": "2025-06-27T16:00:07.679558Z",
     "shell.execute_reply": "2025-06-27T16:00:07.678923Z",
     "shell.execute_reply.started": "2025-06-27T16:00:07.676069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:00:07.879619Z",
     "iopub.status.busy": "2025-06-27T16:00:07.879422Z",
     "iopub.status.idle": "2025-06-27T16:00:08.736664Z",
     "shell.execute_reply": "2025-06-27T16:00:08.735870Z",
     "shell.execute_reply.started": "2025-06-27T16:00:07.879605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:00:08.737954Z",
     "iopub.status.busy": "2025-06-27T16:00:08.737729Z",
     "iopub.status.idle": "2025-06-27T16:00:08.742217Z",
     "shell.execute_reply": "2025-06-27T16:00:08.741397Z",
     "shell.execute_reply.started": "2025-06-27T16:00:08.737938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    torch.cuda.set_device(i)\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:09.629398Z",
     "iopub.status.busy": "2025-06-27T13:22:09.629137Z",
     "iopub.status.idle": "2025-06-27T14:31:56.931169Z",
     "shell.execute_reply": "2025-06-27T14:31:56.930594Z",
     "shell.execute_reply.started": "2025-06-27T13:22:09.629375Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T12:41:09.504624Z",
     "iopub.status.busy": "2025-06-27T12:41:09.503829Z",
     "iopub.status.idle": "2025-06-27T12:41:12.808174Z",
     "shell.execute_reply": "2025-06-27T12:41:12.807561Z",
     "shell.execute_reply.started": "2025-06-27T12:41:09.504598Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/kaggle/working\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:36:03.621594Z",
     "iopub.status.busy": "2025-06-27T14:36:03.620936Z",
     "iopub.status.idle": "2025-06-27T14:36:06.760366Z",
     "shell.execute_reply": "2025-06-27T14:36:06.759464Z",
     "shell.execute_reply.started": "2025-06-27T14:36:03.621543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"CLI_model\")\n",
    "tokenizer.save_pretrained(\"CLI_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Saving the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:32:58.970650Z",
     "iopub.status.busy": "2025-06-27T14:32:58.970007Z",
     "iopub.status.idle": "2025-06-27T14:32:59.108616Z",
     "shell.execute_reply": "2025-06-27T14:32:59.108076Z",
     "shell.execute_reply.started": "2025-06-27T14:32:58.970622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"Api_key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:36:18.178324Z",
     "iopub.status.busy": "2025-06-27T14:36:18.177492Z",
     "iopub.status.idle": "2025-06-27T14:36:54.026530Z",
     "shell.execute_reply": "2025-06-27T14:36:54.025914Z",
     "shell.execute_reply.started": "2025-06-27T14:36:18.178298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Push LoRA adapter\n",
    "model.push_to_hub(\"Maarij-Aqeel/CLI_model\", use_temp_dir=False)\n",
    "\n",
    "# Push tokenizer (very important!)\n",
    "tokenizer.push_to_hub(\"Maarij-Aqeel/CLI_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:00:35.944447Z",
     "iopub.status.busy": "2025-06-27T16:00:35.943714Z",
     "iopub.status.idle": "2025-06-27T16:00:42.693266Z",
     "shell.execute_reply": "2025-06-27T16:00:42.692398Z",
     "shell.execute_reply.started": "2025-06-27T16:00:35.944426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:00:42.698158Z",
     "iopub.status.busy": "2025-06-27T16:00:42.697390Z",
     "iopub.status.idle": "2025-06-27T16:00:42.701212Z",
     "shell.execute_reply": "2025-06-27T16:00:42.700529Z",
     "shell.execute_reply.started": "2025-06-27T16:00:42.698131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:03:09.398646Z",
     "iopub.status.busy": "2025-06-27T16:03:09.398358Z",
     "iopub.status.idle": "2025-06-27T16:03:09.404138Z",
     "shell.execute_reply": "2025-06-27T16:03:09.403547Z",
     "shell.execute_reply.started": "2025-06-27T16:03:09.398621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load model in 4-bit (QLoRA)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:03:11.357601Z",
     "iopub.status.busy": "2025-06-27T16:03:11.357140Z",
     "iopub.status.idle": "2025-06-27T16:05:58.174015Z",
     "shell.execute_reply": "2025-06-27T16:05:58.173143Z",
     "shell.execute_reply.started": "2025-06-27T16:03:11.357565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Maarij-Aqeel/CLI_model\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Maarij-Aqeel/CLI_model\", \n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"  # Better device management\n",
    ").eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:05:58.175678Z",
     "iopub.status.busy": "2025-06-27T16:05:58.175429Z",
     "iopub.status.idle": "2025-06-27T16:05:58.179266Z",
     "shell.execute_reply": "2025-06-27T16:05:58.178595Z",
     "shell.execute_reply.started": "2025-06-27T16:05:58.175658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Ensure pad token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:33:29.522872Z",
     "iopub.status.busy": "2025-06-27T16:33:29.522153Z",
     "iopub.status.idle": "2025-06-27T16:33:29.530172Z",
     "shell.execute_reply": "2025-06-27T16:33:29.529240Z",
     "shell.execute_reply.started": "2025-06-27T16:33:29.522844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Run this ONCE after loading your model\n",
    "def generate_cli_command(user_input, model, tokenizer):\n",
    "    \"\"\"Generate CLI command for a given user input\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''You are a CLI command translator. Given a natural language request, output only the exact command(s) needed to accomplish the task. Provide no explanations, descriptions, or additional text - just the raw command(s) that can be directly executed in a terminal.\n",
    "Examples:\n",
    "Input: \"list all files in current directory\"\n",
    "Output: ls -la\n",
    "Input: \"find all Python files\"\n",
    "Output: find . -name \"*.py\"\n",
    "Input: \"show running processes\"\n",
    "Output: ps aux'''\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "    \n",
    "    # Apply chat template and tokenize\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=192\n",
    "    ).to(model.device)\n",
    "    \n",
    "    # Generate\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_new_tokens=64,\n",
    "                do_sample=True,\n",
    "                temperature=0.3,\n",
    "                top_p=0.9,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                use_cache=False,\n",
    "                output_attentions=False,\n",
    "                output_hidden_states=False,\n",
    "                return_dict_in_generate=False\n",
    "            )\n",
    "        \n",
    "        response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract just the command part\n",
    "        if \"Output:\" in response:\n",
    "            command = response.split(\"Output:\")[-1].strip()\n",
    "        else:\n",
    "            # Fallback: get text after the user input\n",
    "            prompt_end = f'\"{user_input}\"'\n",
    "            if prompt_end in response:\n",
    "                command = response.split(prompt_end)[-1].strip()\n",
    "            else:\n",
    "                command = response.split('\\n')[-1].strip()\n",
    "        \n",
    "        return command\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:33:33.279225Z",
     "iopub.status.busy": "2025-06-27T16:33:33.278482Z",
     "iopub.status.idle": "2025-06-27T16:33:33.283801Z",
     "shell.execute_reply": "2025-06-27T16:33:33.283064Z",
     "shell.execute_reply.started": "2025-06-27T16:33:33.279196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def interactive_mode():\n",
    "    \"\"\"Interactive mode for real-time testing\"\"\"\n",
    "    print(\"=== Interactive CLI Command Generator ===\")\n",
    "    print(\"Type your requests (or 'quit' to exit):\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\n> \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "            \n",
    "        print(\"Generating command...\")\n",
    "        command = generate_cli_command(user_input, model, tokenizer)\n",
    "        print(f\"Command: {command}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:33:34.852306Z",
     "iopub.status.busy": "2025-06-27T16:33:34.851594Z",
     "iopub.status.idle": "2025-06-27T17:00:12.346649Z",
     "shell.execute_reply": "2025-06-27T17:00:12.345883Z",
     "shell.execute_reply.started": "2025-06-27T16:33:34.852279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7746397,
     "sourceId": 12290951,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
